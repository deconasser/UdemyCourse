{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/deconasser/UdemyCourse/blob/main/Unet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OuNp5f2r4rM5",
        "outputId": "07165135-fc33-4d46-835b-e5d10d302f1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow\n",
        "!pip install segmentation_models"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "DJXxKSXc5OAH",
        "outputId": "6f981a8a-8391-421c-f5bb-1cd6324f0382"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.4.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.7.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n",
            "Collecting segmentation_models\n",
            "  Downloading segmentation_models-1.0.1-py3-none-any.whl (33 kB)\n",
            "Collecting keras-applications<=1.0.8,>=1.0.7 (from segmentation_models)\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.7/50.7 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting image-classifiers==1.0.0 (from segmentation_models)\n",
            "  Downloading image_classifiers-1.0.0-py3-none-any.whl (19 kB)\n",
            "Collecting efficientnet==1.0.0 (from segmentation_models)\n",
            "  Downloading efficientnet-1.0.0-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from efficientnet==1.0.0->segmentation_models) (0.19.3)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from keras-applications<=1.0.8,>=1.0.7->segmentation_models) (1.25.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras-applications<=1.0.8,>=1.0.7->segmentation_models) (3.9.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (1.11.4)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (3.3)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (9.4.0)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (2.31.6)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (2024.7.2)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (1.6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (24.1)\n",
            "Installing collected packages: keras-applications, image-classifiers, efficientnet, segmentation_models\n",
            "Successfully installed efficientnet-1.0.0 image-classifiers-1.0.0 keras-applications-1.0.8 segmentation_models-1.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install albumentations"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "_T4SPKJp5RiD",
        "outputId": "0bf16d45-ff97-455c-a364-e319e9518aa4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: albumentations in /usr/local/lib/python3.10/dist-packages (1.3.1)\n",
            "Requirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.10/dist-packages (from albumentations) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from albumentations) (1.11.4)\n",
            "Requirement already satisfied: scikit-image>=0.16.1 in /usr/local/lib/python3.10/dist-packages (from albumentations) (0.19.3)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from albumentations) (6.0.1)\n",
            "Requirement already satisfied: qudida>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from albumentations) (0.0.4)\n",
            "Requirement already satisfied: opencv-python-headless>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from albumentations) (4.10.0.84)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from qudida>=0.0.4->albumentations) (1.2.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from qudida>=0.0.4->albumentations) (4.12.2)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations) (3.3)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations) (9.4.0)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations) (2.31.6)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations) (2024.7.2)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations) (1.6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations) (24.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (3.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"SM_FRAMEWORK\"] = \"tf.keras\"\n",
        "\n",
        "from tensorflow import keras\n",
        "import segmentation_models as sm\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "import albumentations as A\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard\n",
        "from albumentations import Compose, HorizontalFlip, RandomRotate90\n",
        "\n",
        "import numpy as np\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
        "from albumentations import (\n",
        "    Compose,\n",
        "    RandomRotate90,\n",
        "    Flip,\n",
        "    Transpose,\n",
        "    ElasticTransform,\n",
        "    GridDistortion,\n",
        "    OpticalDistortion,\n",
        "    RandomBrightnessContrast,\n",
        "    HorizontalFlip,\n",
        "    VerticalFlip,\n",
        "    RandomGamma,\n",
        "    RGBShift,\n",
        ")"
      ],
      "metadata": {
        "id": "_ZHLYl6x5T_N",
        "outputId": "d786fbb4-5771-43ba-8100-9c7eed283d0c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Segmentation Models: using `tf.keras` framework.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_gt(gt_image):\n",
        "    gt_image = np.array(gt_image, dtype=np.uint8)\n",
        "    num_classes = 3\n",
        "    gt_one_hot = np.zeros((gt_image.shape[0], gt_image.shape[1], num_classes), dtype=np.float32)\n",
        "\n",
        "    # Lớp 0: Màu đen (background)\n",
        "    gt_one_hot[:, :, 0] = (gt_image == 0).all(axis=-1).astype(np.float32)\n",
        "    # Lớp 1: Màu xanh lá cây (lành tính)\n",
        "    gt_one_hot[:, :, 1] = (gt_image[:, :, 1] == 255).astype(np.float32) # channel 1 (G) == 255\n",
        "    # Lớp 2: Màu đỏ (ác tính)\n",
        "    gt_one_hot[:, :, 2] = (gt_image[:, :, 0] == 255).astype(np.float32) # channel 0 (R) == 255\n",
        "\n",
        "    return gt_one_hot\n",
        "\n",
        "def load_data(image_path, mask_path, img_size=(256, 256)):\n",
        "    images = []\n",
        "    masks = []\n",
        "\n",
        "    image_files = sorted(os.listdir(image_path))\n",
        "    mask_files = sorted(os.listdir(mask_path))\n",
        "\n",
        "    for img_file, mask_file in zip(image_files, mask_files):\n",
        "        img = load_img(os.path.join(image_path, img_file), target_size=img_size)\n",
        "        img = img_to_array(img) / 255.0\n",
        "\n",
        "        mask = load_img(os.path.join(mask_path, mask_file), target_size=img_size)\n",
        "        mask = img_to_array(mask)\n",
        "\n",
        "        mask = preprocess_gt(mask)\n",
        "\n",
        "        images.append(img)\n",
        "        masks.append(mask)\n",
        "\n",
        "    images = np.array(images, dtype=np.float32)\n",
        "    masks = np.array(masks, dtype=np.float32)\n",
        "\n",
        "    return images, masks\n",
        "\n",
        "# Đường dẫn tới dữ liệu\n",
        "train_images_path = '/content/drive/MyDrive/Unet/data/train'\n",
        "train_masks_path = '/content/drive/MyDrive/Unet/data/train_gt'"
      ],
      "metadata": {
        "id": "k6nDZRtN5caN"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_images, train_masks = load_data(train_images_path, train_masks_path)"
      ],
      "metadata": {
        "id": "IymdsNDj5jQV"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test = load_img(\"/content/drive/MyDrive/Unet/data/train_gt/0081835cf877e004e8bfb905b78a9139.jpeg\")\n",
        "test = img_to_array(test)\n",
        "test = preprocess_gt(test)\n",
        "print(test[0][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u9Zlka5CDe0s",
        "outputId": "2798475f-f2c9-4fd9-abdc-dcc979943e3f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1. 0. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def augment_data(images, masks):\n",
        "  aug = Compose([\n",
        "      HorizontalFlip(p=0.5),\n",
        "      RandomRotate90(p=0.5),\n",
        "      A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=45, p=0.5),\n",
        "      A.RandomBrightnessContrast(p=0.5)\n",
        "  ])\n",
        "  augmented_images = []\n",
        "  augmented_masks = []\n",
        "  for img, mask in zip(images, masks):\n",
        "      augmented = aug(image=img, mask=mask)\n",
        "      augmented_images.append(augmented['image'])\n",
        "      augmented_masks.append(augmented['mask'])\n",
        "  return np.array(augmented_images), np.array(augmented_masks)"
      ],
      "metadata": {
        "id": "DqhP2e_4pKmf"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "augmented_images, augmented_masks = augment_data(train_images, train_masks)"
      ],
      "metadata": {
        "id": "R_XnugJbpM6m"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "def weighted_dice_loss(y_true, y_pred):\n",
        "  smooth = 1.0\n",
        "  class_weights = tf.constant([0.5, 2.0, 2.0], dtype=tf.float32)\n",
        "\n",
        "  # Apply class weights\n",
        "  y_true_weighted = y_true * class_weights\n",
        "  y_pred_weighted = y_pred * class_weights\n",
        "\n",
        "  y_true_f = tf.keras.backend.flatten(y_true_weighted)\n",
        "  y_pred_f = tf.keras.backend.flatten(y_pred_weighted)\n",
        "  intersection = tf.keras.backend.sum(y_true_f * y_pred_f)\n",
        "\n",
        "  return 1 - (2. * intersection + smooth) / (tf.keras.backend.sum(y_true_f) + tf.keras.backend.sum(y_pred_f) + smooth)\n",
        "\n",
        "\n",
        "def iou_metric(y_true, y_pred):\n",
        "  y_true_f = tf.keras.backend.flatten(y_true)\n",
        "  y_pred_f = tf.keras.backend.flatten(y_pred)\n",
        "  intersection = tf.keras.backend.sum(y_true_f * y_pred_f)\n",
        "  union = tf.keras.backend.sum(y_true_f) + tf.keras.backend.sum(y_pred_f) - intersection\n",
        "  return intersection / union\n",
        "\n",
        "def dice_coefficient(y_true, y_pred):\n",
        "  smooth = 1.0\n",
        "  y_true_f = tf.keras.backend.flatten(y_true)\n",
        "  y_pred_f = tf.keras.backend.flatten(y_pred)\n",
        "  intersection = tf.keras.backend.sum(y_true_f * y_pred_f)\n",
        "  return (2. * intersection + smooth) / (tf.keras.backend.sum(y_true_f) + tf.keras.backend.sum(y_pred_f) + smooth)\n",
        "\n",
        "def unet_model(input_size=(256, 256, 3)):\n",
        "    inputs = layers.Input(input_size)\n",
        "\n",
        "    # Encoder\n",
        "    conv1 = layers.Conv2D(64, 3, activation='relu', padding='same')(inputs)\n",
        "    conv1 = layers.Conv2D(64, 3, activation='relu', padding='same')(conv1)\n",
        "    pool1 = layers.MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "\n",
        "    conv2 = layers.Conv2D(128, 3, activation='relu', padding='same')(pool1)\n",
        "    conv2 = layers.Conv2D(128, 3, activation='relu', padding='same')(conv2)\n",
        "    pool2 = layers.MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "\n",
        "    conv3 = layers.Conv2D(256, 3, activation='relu', padding='same')(pool2)\n",
        "    conv3 = layers.Conv2D(256, 3, activation='relu', padding='same')(conv3)\n",
        "    pool3 = layers.MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "\n",
        "    conv4 = layers.Conv2D(512, 3, activation='relu', padding='same')(pool3)\n",
        "    conv4 = layers.Conv2D(512, 3, activation='relu', padding='same')(conv4)\n",
        "    pool4 = layers.MaxPooling2D(pool_size=(2, 2))(conv4)\n",
        "\n",
        "\n",
        "    # Decoder\n",
        "\n",
        "    up7 = layers.Conv2D(256, 2, activation='relu', padding='same')(layers.UpSampling2D(size=(2, 2))(conv4))\n",
        "    merge7 = layers.concatenate([conv3, up7], axis=3)\n",
        "    conv7 = layers.Conv2D(256, 3, activation='relu', padding='same')(merge7)\n",
        "    conv7 = layers.Conv2D(256, 3, activation='relu', padding='same')(conv7)\n",
        "\n",
        "    up8 = layers.Conv2D(128, 2, activation='relu', padding='same')(layers.UpSampling2D(size=(2, 2))(conv7))\n",
        "    merge8 = layers.concatenate([conv2, up8], axis=3)\n",
        "    conv8 = layers.Conv2D(128, 3, activation='relu', padding='same')(merge8)\n",
        "    conv8 = layers.Conv2D(128, 3, activation='relu', padding='same')(conv8)\n",
        "\n",
        "    up9 = layers.Conv2D(64, 2, activation='relu', padding='same')(layers.UpSampling2D(size=(2, 2))(conv8))\n",
        "    merge9 = layers.concatenate([conv1, up9], axis=3)\n",
        "    conv9 = layers.Conv2D(64, 3, activation='relu', padding='same')(merge9)\n",
        "    conv9 = layers.Conv2D(64, 3, activation='relu', padding='same')(conv9)\n",
        "\n",
        "    # Final layer with softmax activation\n",
        "    segmentation_output = layers.Conv2D(3, 1, activation='softmax', name='segmentation')(conv9)\n",
        "\n",
        "    model = models.Model(inputs=inputs, outputs=segmentation_output)\n",
        "    model.compile(optimizer=Adam(learning_rate=1e-4), loss=weighted_dice_loss, metrics=[iou_metric, dice_coefficient])\n",
        "\n",
        "    return model\n",
        "\n",
        "model = unet_model()\n"
      ],
      "metadata": {
        "id": "JhDBoMfn5mNk"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "# Tạo thư mục lưu trữ kết quả huấn luyện\n",
        "log_dir = os.path.join(\"/content/drive/MyDrive/Unet/logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "os.makedirs(log_dir, exist_ok=True)\n",
        "\n",
        "# Callbacks\n",
        "checkpoint_callback = ModelCheckpoint(\n",
        "    filepath='best_model.keras',\n",
        "    monitor='val_loss',\n",
        "    save_best_only=True,\n",
        "    mode='min',\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "early_stopping_callback = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=10,\n",
        "    mode='min',\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "tensorboard_callback = TensorBoard(\n",
        "    log_dir=log_dir,\n",
        "    histogram_freq=1\n",
        ")\n",
        "\n",
        "callbacks = [checkpoint_callback, early_stopping_callback, tensorboard_callback]\n"
      ],
      "metadata": {
        "id": "vGymiAWy6eb6"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(augmented_images, augmented_masks, test_size=0.2, random_state=42)\n",
        "\n",
        "history = model.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    epochs=50,\n",
        "    batch_size=16,\n",
        "    validation_data=(X_val, y_val),\n",
        "    callbacks=callbacks,\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mp6CKfOZ8Xms",
        "outputId": "29210f43-5a98-4a72-da07-61f3b256cd8e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.6190 - iou_metric: 0.7557 - dice_coefficient: 0.8211\n",
            "Epoch 1: val_loss improved from inf to 0.52417, saving model to best_model.keras\n",
            "50/50 [==============================] - 93s 1s/step - loss: 0.6190 - iou_metric: 0.7557 - dice_coefficient: 0.8211 - val_loss: 0.5242 - val_iou_metric: 0.9270 - val_dice_coefficient: 0.9620\n",
            "Epoch 2/50\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.5213 - iou_metric: 0.9358 - dice_coefficient: 0.9668\n",
            "Epoch 2: val_loss did not improve from 0.52417\n",
            "50/50 [==============================] - 44s 874ms/step - loss: 0.5213 - iou_metric: 0.9358 - dice_coefficient: 0.9668 - val_loss: 0.5242 - val_iou_metric: 0.9270 - val_dice_coefficient: 0.9620\n",
            "Epoch 3/50\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.5213 - iou_metric: 0.9358 - dice_coefficient: 0.9668\n",
            "Epoch 3: val_loss did not improve from 0.52417\n",
            "50/50 [==============================] - 46s 915ms/step - loss: 0.5213 - iou_metric: 0.9358 - dice_coefficient: 0.9668 - val_loss: 0.5242 - val_iou_metric: 0.9270 - val_dice_coefficient: 0.9620\n",
            "Epoch 4/50\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.5213 - iou_metric: 0.9358 - dice_coefficient: 0.9668\n",
            "Epoch 4: val_loss did not improve from 0.52417\n",
            "50/50 [==============================] - 44s 876ms/step - loss: 0.5213 - iou_metric: 0.9358 - dice_coefficient: 0.9668 - val_loss: 0.5242 - val_iou_metric: 0.9270 - val_dice_coefficient: 0.9620\n",
            "Epoch 5/50\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.5213 - iou_metric: 0.9358 - dice_coefficient: 0.9668\n",
            "Epoch 5: val_loss did not improve from 0.52417\n",
            "50/50 [==============================] - 44s 873ms/step - loss: 0.5213 - iou_metric: 0.9358 - dice_coefficient: 0.9668 - val_loss: 0.5242 - val_iou_metric: 0.9270 - val_dice_coefficient: 0.9620\n",
            "Epoch 6/50\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.5213 - iou_metric: 0.9358 - dice_coefficient: 0.9668\n",
            "Epoch 6: val_loss did not improve from 0.52417\n",
            "50/50 [==============================] - 43s 872ms/step - loss: 0.5213 - iou_metric: 0.9358 - dice_coefficient: 0.9668 - val_loss: 0.5242 - val_iou_metric: 0.9270 - val_dice_coefficient: 0.9620\n",
            "Epoch 7/50\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.5213 - iou_metric: 0.9358 - dice_coefficient: 0.9668\n",
            "Epoch 7: val_loss did not improve from 0.52417\n",
            "50/50 [==============================] - 46s 929ms/step - loss: 0.5213 - iou_metric: 0.9358 - dice_coefficient: 0.9668 - val_loss: 0.5242 - val_iou_metric: 0.9270 - val_dice_coefficient: 0.9620\n",
            "Epoch 8/50\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.5213 - iou_metric: 0.9358 - dice_coefficient: 0.9668\n",
            "Epoch 8: val_loss did not improve from 0.52417\n",
            "50/50 [==============================] - 44s 879ms/step - loss: 0.5213 - iou_metric: 0.9358 - dice_coefficient: 0.9668 - val_loss: 0.5242 - val_iou_metric: 0.9270 - val_dice_coefficient: 0.9620\n",
            "Epoch 9/50\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.5213 - iou_metric: 0.9358 - dice_coefficient: 0.9668\n",
            "Epoch 9: val_loss did not improve from 0.52417\n",
            "50/50 [==============================] - 44s 883ms/step - loss: 0.5213 - iou_metric: 0.9358 - dice_coefficient: 0.9668 - val_loss: 0.5242 - val_iou_metric: 0.9270 - val_dice_coefficient: 0.9620\n",
            "Epoch 10/50\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.5213 - iou_metric: 0.9358 - dice_coefficient: 0.9668\n",
            "Epoch 10: val_loss did not improve from 0.52417\n",
            "50/50 [==============================] - 44s 873ms/step - loss: 0.5213 - iou_metric: 0.9358 - dice_coefficient: 0.9668 - val_loss: 0.5242 - val_iou_metric: 0.9270 - val_dice_coefficient: 0.9620\n",
            "Epoch 11/50\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.5213 - iou_metric: 0.9358 - dice_coefficient: 0.9668\n",
            "Epoch 11: val_loss did not improve from 0.52417\n",
            "50/50 [==============================] - 44s 874ms/step - loss: 0.5213 - iou_metric: 0.9358 - dice_coefficient: 0.9668 - val_loss: 0.5242 - val_iou_metric: 0.9270 - val_dice_coefficient: 0.9620\n",
            "Epoch 11: early stopping\n"
          ]
        }
      ]
    }
  ]
}